{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "pygments_lexer": "ipython3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 03 \u2014 Validate documents against the policy\n",
        "\n",
        "Now the inspector walks every street with two things in hand, the census and the policy. For each run it checks the rules and writes a one-line violation when a rule is broken. At the end it writes a short verdict for the whole file. Small, predictable, boring. Exactly what you want from a judge."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import pandas as pd, json\n",
        "\n",
        "CWD = Path.cwd()\n",
        "ROOT = (CWD if CWD.name != \"notebooks\" else CWD.parent).resolve()\n",
        "\n",
        "FEAT = ROOT / \"reports\" / \"features\"\n",
        "POLICY = ROOT / \"reports\" / \"policy\" / \"policy.json\"\n",
        "OUT = ROOT / \"reports\" / \"validation\"\n",
        "OUT.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "with open(POLICY, \"r\", encoding=\"utf-8\") as f:\n",
        "    policy = json.load(f)\n",
        "\n",
        "def ok_color(c, allowed):\n",
        "    if not allowed:\n",
        "        return True\n",
        "    if c is None or c != c:  # NaN\n",
        "        return True\n",
        "    return str(c).upper() in {x.upper() for x in allowed}\n",
        "\n",
        "def validate_file(csv_path: Path, policy: dict) -> pd.DataFrame:\n",
        "    df = pd.read_csv(csv_path)\n",
        "    v = []\n",
        "    for _, r in df.iterrows():\n",
        "        kind = r.get(\"kind\")\n",
        "        fam = r.get(\"font_family\")\n",
        "        size = r.get(\"font_size_pt\")\n",
        "        col  = r.get(\"color_rgb\")\n",
        "\n",
        "        if kind == \"docx_run\":\n",
        "            rule = policy[\"fonts\"].get(\"docx\", {}).get(\"body\", {})\n",
        "            if rule.get(\"family\") and pd.notna(fam) and fam != rule[\"family\"]:\n",
        "                v.append((r[\"file\"], \"docx.font_family\", fam, rule[\"family\"]))\n",
        "            if rule.get(\"size_pt\") and pd.notna(size) and float(size) != float(rule[\"size_pt\"]):\n",
        "                v.append((r[\"file\"], \"docx.font_size_pt\", size, rule[\"size_pt\"]))\n",
        "            if not ok_color(col, policy.get(\"colors_rgb\", [])):\n",
        "                v.append((r[\"file\"], \"docx.color_rgb\", col, \"palette\"))\n",
        "\n",
        "        if kind == \"pptx_run\":\n",
        "            pr = policy[\"fonts\"].get(\"pptx\", {})\n",
        "            fam_req = pr.get(\"family\")\n",
        "            body_min = pr.get(\"body_min_pt\")\n",
        "            title_min = pr.get(\"title_min_pt\")\n",
        "            if fam_req and pd.notna(fam) and fam != fam_req:\n",
        "                v.append((r[\"file\"], \"pptx.font_family\", fam, fam_req))\n",
        "            if pd.notna(size):\n",
        "                s = float(size)\n",
        "                # heuristic: if size >= 22 it is heading-like; otherwise body-like\n",
        "                if s < float(body_min):\n",
        "                    v.append((r[\"file\"], \"pptx.body_too_small\", s, f\">= {body_min}\"))\n",
        "                if s >= 22 and s < float(title_min):\n",
        "                    v.append((r[\"file\"], \"pptx.title_too_small\", s, f\">= {title_min}\"))\n",
        "            if not ok_color(col, policy.get(\"colors_rgb\", [])):\n",
        "                v.append((r[\"file\"], \"pptx.color_rgb\", col, \"palette\"))\n",
        "    return pd.DataFrame(v, columns=[\"file\", \"rule\", \"observed\", \"expected\"])"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Run validation over all feature CSVs\n",
        "summ = []\n",
        "for csv in FEAT.glob(\"*.features.csv\"):\n",
        "    v = validate_file(csv, policy)\n",
        "    v.to_csv(OUT / f\"{csv.stem}.violations.csv\", index=False)\n",
        "    summ.append({\"file\": csv.name, \"violations\": len(v)})\n",
        "summary = pd.DataFrame(summ).sort_values(\"violations\", ascending=False)\n",
        "summary.to_csv(OUT / \"summary.csv\", index=False)\n",
        "print(\"Wrote per-file violations and summary to\", OUT)\n",
        "display(summary.head(10))"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "# Peek into worst offender, if any\n",
        "if not summary.empty and summary[\"violations\"].max() > 0:\n",
        "    worst = summary.iloc[0][\"file\"]\n",
        "    import pandas as pd\n",
        "    dfv = pd.read_csv(OUT / worst.replace(\".features.csv\", \".violations.csv\"))\n",
        "    display(dfv.head(20))"
      ]
    }
  ]
}